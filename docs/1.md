# 入门

## 1\. 介绍

[快速开始](#quickstart) 会介绍如何运行一个单机版的Standalone模式HBase.

## 2\. 快速开始 - Standalone HBase

本章节介绍了在单机安装HBase的方法。会引导你通过`hbase shell`创建一个表，插入一行，然后执行put和scan指令，开启和关闭这张表，开启和停止HBase。只要10分钟就可以完成以下的操作。

除了下载HBase外，此过程不到10分钟就能完成。

### 2.1\. JDK 版本要求

HBase要求安装JDK。有关支持JDK版本的信息，请参阅[Java](#java)。

### 2.2\. HBase开始

#### 过程：下载、配置和启动 Standalone HBase

1. 选择一个[Apache下载镜像]（https://www.apache.org/dyn/closer.lua/hbase/）。 建议点击顶部链接，进入_HBase Releases_ 点击_stable_的文件夹，然后下载将以_tar.gz_结尾的二进制文件到本地。暂时不要下载以_src.tar.gz_结尾的文件。

2. 解压缩，然后进入到那个要解压的目录.

   ```
   $ tar xzvf hbase-3.0.0-SNAPSHOT-bin.tar.gz
   $ cd hbase-3.0.0-SNAPSHOT/
   ```

3. 在启动HBase之前，您需要设置`JAVA_HOME`环境变量。您可以通过操作系统的常用设置来设置变量，HBase也提供了一个中心机制_conf/hbase-env.sh_。编辑此文件，取消注释以`JAVA_HOME`开头的行，并将其设置为适合您的操作系统的路径。应将`JAVA_HOME`变量设置为包含可执行文件_bin/java_的目录。如今，大多数Linux操作系统都提供了一种机制，例如RHEL或CentOS上的/usr/bin/alternatives，可以方便切换环境。在这种情况下，您可以将`JAVA_HOME`设置为包含_bin/java_的符号链接的目录，通常为_/usr_。

   ```
   JAVA_HOME=/usr
   ```

4. 编辑HBase主配置文件_conf/hbase-site.xml_. 
   此时，您需要在本地文件系统上指定HBase和ZooKeeper数据存储目录，并知晓一些风险。默认情况下，HBase会在/tmp下创建一个新目录，但是许多服务为在重新启动时会删除_/tmp_的内容，因此您需要将数据存储在其他位置。以下配置文件处在_hbase_,名为`testuser`的用户的主目录中。首次安装HBase为空，可以将`<property>`标记粘贴在`<configuration>`内。

   示例 1\.  _hbase-site.xml_  Standalone HBase配置

   ```
   <configuration>
     <property>
       <name>hbase.rootdir</name>
       <value>file:///home/testuser/hbase</value>
     </property>
     <property>
       <name>hbase.zookeeper.property.dataDir</name>
       <value>/home/testuser/zookeeper</value>
     </property>
     <property>
       <name>hbase.unsafe.stream.capability.enforce</name>
       <value>false</value>
       <description>
         Controls whether HBase will check for stream capabilities (hflush/hsync).
   
         Disable this if you intend to run on LocalFileSystem, denoted by a rootdir
         with the 'file://' scheme, but be mindful of the NOTE below.
   
         WARNING: Setting this to false blinds you to potential data loss and
         inconsistent system state in the event of process and/or node failures. If
         HBase is complaining of an inability to use hsync or hflush it's most
         likely not a false positive.
       </description>
     </property>
   </configuration>
   ```
   您不需要创建HBase数据目录。 HBase会自动创建。如果您想要自定义创建目录，HBase将尝试进行迁移 。

   > 上例中的_hbase.rootdir_指向_local filesystem_中的目录。 'file：//'前缀是表示本地文件系。您应该将配置示例中的警告牢记在心。在Standalone模式下，HBase利用Apache Hadoopd的本地文件存储。但是这种方式并不能保证HBase运行的持久性。这只是适用于于本地开发和测试用例，可以很好的控制集群故障的成本。它不适合生产部署，否则你会丢失数据。

为在HDFS上部署HBase, 可以将 _hbase.rootdir_ 指向如: _hdfs://namenode.example.org:8020/hbase_. 有关此变量的更多用法，可查看章节基于HDFS部署Standalone HBase.

1. 脚本_bin/start-hbase.sh_为启动HBase提供了方便的途径。执行命令，在标准输出的日志里可以看到HBase启动成功的消息。你可以使用 `jps` 命令来确认你有一个正在运行的进行 `HMaster`。在 HBase 的Standalone模式中，所有的服务都运行在同一JVM中，如 HMaster，单例的 HRegionServer 和 ZooKeeper 的守护进程。可以前往Web UI_[http://localhost:16010](http://localhost:16010)_查看HBase.

   > Java必须安装且可用. 如果你收到错误提示，Java未安装，可能java位于非标准位置，你可以编辑_conf/hbase-env.sh_ ,修改 `JAVA_HOME` 路径，并确保包含 _bin/java_.

#### 过程: 首次使用HBase

1. 连接HBase

   在HBase安装目录_bin/_ 目录下使用`hbase shell`命令连接正在运行的HBase实例。 在下面这个例子中，当你启动HBase Shell 并忽略一些用法和版本信息后，HBase Shell 是以字符`>` 结尾。

   ```
   $ ./bin/hbase shell
   hbase(main):001:0>
   ```

2. 预览 HBase Shell 的帮助文本

   输入`help`并回车, 可以看到HBase Shell的基本信息和一些示例命令.请注意，表名，行，列都必须用引号字符括起来。

3. 创建表

   使用 `create`创建一个表，你必须执行一个表名和列族名。

   ```
   hbase(main):001:0> create 'test', 'cf'
   0 row(s) in 0.4170 seconds
   
   => Hbase::Table - test
   ```

4. 表信息

   使用 `list` 查看存在表

   ```
   hbase(main):002:0> list 'test'
   TABLE
   test
   1 row(s) in 0.0180 seconds
   
   => ["test"]
   ```

   使用 `describe` 查看表细节及配置

   ```
   hbase(main):003:0> describe 'test'
   Table test is ENABLED
   test
   COLUMN FAMILIES DESCRIPTION
   {NAME => 'cf', VERSIONS => '1', EVICT_BLOCKS_ON_CLOSE => 'false', NEW_VERSION_BEHAVIOR => 'false', KEEP_DELETED_CELLS => 'FALSE', CACHE_DATA_ON_WRITE =>
   'false', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', MIN_VERSIONS => '0', REPLICATION_SCOPE => '0', BLOOMFILTER => 'ROW', CACHE_INDEX_ON_WRITE => 'f
   alse', IN_MEMORY => 'false', CACHE_BLOOMS_ON_WRITE => 'false', PREFETCH_BLOCKS_ON_OPEN => 'false', COMPRESSION => 'NONE', BLOCKCACHE => 'true', BLOCKSIZE
    => '65536'}
   1 row(s)
   Took 0.9998 seconds
   ```

5. 插入数据

   使用 `put` 插入数据

   ```
   hbase(main):003:0> put 'test', 'row1', 'cf:a', 'value1'
   0 row(s) in 0.0850 seconds
   
   hbase(main):004:0> put 'test', 'row2', 'cf:b', 'value2'
   0 row(s) in 0.0110 seconds
   
   hbase(main):005:0> put 'test', 'row3', 'cf:c', 'value3'
   0 row(s) in 0.0100 seconds
   ```

   在这里，我们往`test`表中依次插入了三条数据。首先插入了一条rowkey为`row1`、列为`cf:a`、值为`value1`的数据。HBase中的列是包含列族前缀的，在这个例子中，冒号前的为列 `cf`，冒号后的为列限定符 `a` 。

6. 扫描全部数据

   从HBase获取数据的途径之一就是 `scan` 。使用 scan 命令扫描表数据。你可以对扫描做限制，不过现在，获取全部的数据。

   ```
   hbase(main):006:0> scan 'test'
   ROW                                      COLUMN+CELL
    row1                                    column=cf:a, timestamp=1421762485768, value=value1
    row2                                    column=cf:b, timestamp=1421762491785, value=value2
    row3                                    column=cf:c, timestamp=1421762496210, value=value3
   3 row(s) in 0.0230 seconds
   ```

7. 获取一条数据

   使用 `get` 命令一次获取一条数据。

   ```
   hbase(main):007:0> get 'test', 'row1'
   COLUMN                                   CELL
    cf:a                                    timestamp=1421762485768, value=value1
   1 row(s) in 0.0350 seconds
   ```

8. 禁用表

   如果你想删除一个表或者改变表的设置，以及一些其他的场景，首先你需要使用 `disable` 命令禁用表。你可以使用 `enable` 命令“反禁用”即启用表。

   ```
   hbase(main):008:0> disable 'test'
   0 row(s) in 1.1820 seconds
   
   hbase(main):009:0> enable 'test'
   0 row(s) in 0.1770 seconds
   ```

   Disable the table again if you tested the `enable` command above:

   ```
   hbase(main):010:0> disable 'test'
   0 row(s) in 1.1820 seconds
   ```

9. 删除表

   使用 `drop` 命令删除一个表。

   ```
   hbase(main):011:0> drop 'test'
   0 row(s) in 0.1370 seconds
   ```

10. 退出HBase Shell.

    使用`quit`命令退出命令行并从集群断开连接。HBase 仍然在后台运行。

#### 过程: 停止HBase

1. 脚本 _bin/start-hbase.sh_ 这个脚本提供了便利的启动所有 HBase 服务，同样地， _bin/stop-hbase.sh_  脚本用来停止所有HBase服务。

   ```
   $ ./bin/stop-hbase.sh
   stopping hbase....................
   $
   ```

2. 在使用这个命令后，它可能需要过几分钟才能停掉服务进程。可以使用 `jps` 确认 HMaster 和 HRegionServer 进程是否关闭。

上面已经向您展示了如何启动和停止HBase的Standalone实例。在下一节中，我们将简要介绍HBase其他部署模式。

### 2.3\. Pseudo-Distributed Local Install

After working your way through [quickstart](#quickstart) standalone mode, you can re-configure HBase to run in pseudo-distributed mode. Pseudo-distributed mode means that HBase still runs completely on a single host, but each HBase daemon (HMaster, HRegionServer, and ZooKeeper) runs as a separate process: in standalone mode all daemons ran in one jvm process/instance. By default, unless you configure the `hbase.rootdir` property as described in [quickstart](#quickstart), your data is still stored in _/tmp/_. In this walk-through, we store your data in HDFS instead, assuming you have HDFS available. You can skip the HDFS configuration to continue storing your data in the local filesystem.

> Hadoop Configuratio
>
> This procedure assumes that you have configured Hadoop and HDFS on your local system and/or a remote system, and that they are running and available. It also assumes you are using Hadoop 2. The guide on [Setting up a Single Node Cluster](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html) in the Hadoop documentation is a good starting point.

1. Stop HBase if it is running.

   If you have just finished [quickstart](#quickstart) and HBase is still running, stop it. This procedure will create a totally new directory where HBase will store its data, so any databases you created before will be lost.

2. Configure HBase.

   Edit the _hbase-site.xml_ configuration. First, add the following property which directs HBase to run in distributed mode, with one JVM instance per daemon.

   ```
   <property>
     <name>hbase.cluster.distributed</name>
     <value>true</value>
   </property>
   ```

   Next, change the `hbase.rootdir` from the local filesystem to the address of your HDFS instance, using the `hdfs:////` URI syntax. In this example, HDFS is running on the localhost at port 8020\. Be sure to either remove the entry for `hbase.unsafe.stream.capability.enforce` or set it to true.

   ```
   <property>
     <name>hbase.rootdir</name>
     <value>hdfs://localhost:8020/hbase</value>
   </property>
   ```

   You do not need to create the directory in HDFS. HBase will do this for you. If you create the directory, HBase will attempt to do a migration, which is not what you want.

3. Start HBase.

   Use the _bin/start-hbase.sh_ command to start HBase. If your system is configured correctly, the `jps` command should show the HMaster and HRegionServer processes running.

4. Check the HBase directory in HDFS.

   If everything worked correctly, HBase created its directory in HDFS. In the configuration above, it is stored in _/hbase/_ on HDFS. You can use the `hadoop fs` command in Hadoop’s _bin/_ directory to list this directory.

   ```
   $ ./bin/hadoop fs -ls /hbase
   Found 7 items
   drwxr-xr-x   - hbase users          0 2014-06-25 18:58 /hbase/.tmp
   drwxr-xr-x   - hbase users          0 2014-06-25 21:49 /hbase/WALs
   drwxr-xr-x   - hbase users          0 2014-06-25 18:48 /hbase/corrupt
   drwxr-xr-x   - hbase users          0 2014-06-25 18:58 /hbase/data
   -rw-r--r--   3 hbase users         42 2014-06-25 18:41 /hbase/hbase.id
   -rw-r--r--   3 hbase users          7 2014-06-25 18:41 /hbase/hbase.version
   drwxr-xr-x   - hbase users          0 2014-06-25 21:49 /hbase/oldWALs
   ```

5. Create a table and populate it with data.

   You can use the HBase Shell to create a table, populate it with data, scan and get values from it, using the same procedure as in [shell exercises](#shell_exercises).

6. Start and stop a backup HBase Master (HMaster) server.

   > Running multiple HMaster instances on the same hardware does not make sense in a production environment, in the same way that running a pseudo-distributed cluster does not make sense for production. This step is offered for testing and learning purposes only.

   The HMaster server controls the HBase cluster. You can start up to 9 backup HMaster servers, which makes 10 total HMasters, counting the primary. To start a backup HMaster, use the `local-master-backup.sh`. For each backup master you want to start, add a parameter representing the port offset for that master. Each HMaster uses two ports (16000 and 16010 by default). The port offset is added to these ports, so using an offset of 2, the backup HMaster would use ports 16002 and 16012. The following command starts 3 backup servers using ports 16002/16012, 16003/16013, and 16005/16015.

   ```
   $ ./bin/local-master-backup.sh start 2 3 5
   ```

   To kill a backup master without killing the entire cluster, you need to find its process ID (PID). The PID is stored in a file with a name like _/tmp/hbase-USER-X-master.pid_. The only contents of the file is the PID. You can use the `kill -9` command to kill that PID. The following command will kill the master with port offset 1, but leave the cluster running:

   ```
   $ cat /tmp/hbase-testuser-1-master.pid |xargs kill -9
   ```

7. Start and stop additional RegionServers

   The HRegionServer manages the data in its StoreFiles as directed by the HMaster. Generally, one HRegionServer runs per node in the cluster. Running multiple HRegionServers on the same system can be useful for testing in pseudo-distributed mode. The `local-regionservers.sh` command allows you to run multiple RegionServers. It works in a similar way to the `local-master-backup.sh` command, in that each parameter you provide represents the port offset for an instance. Each RegionServer requires two ports, and the default ports are 16020 and 16030. Since HBase version 1.1.0, HMaster doesn’t use region server ports, this leaves 10 ports (16020 to 16029 and 16030 to 16039) to be used for RegionServers. For supporting additional RegionServers, set environment variables HBASE_RS_BASE_PORT and HBASE_RS_INFO_BASE_PORT to appropriate values before running script `local-regionservers.sh`. e.g. With values 16200 and 16300 for base ports, 99 additional RegionServers can be supported, on a server. The following command starts four additional RegionServers, running on sequential ports starting at 16022/16032 (base ports 16020/16030 plus 2).

   ```
   $ .bin/local-regionservers.sh start 2 3 4 5
   ```

   To stop a RegionServer manually, use the `local-regionservers.sh` command with the `stop` parameter and the offset of the server to stop.

   ```
   $ .bin/local-regionservers.sh stop 3
   ```

8. Stop HBase.

   You can stop HBase the same way as in the [quickstart](#quickstart) procedure, using the _bin/stop-hbase.sh_ command.

### 2.4\. Advanced - Fully Distributed

In reality, you need a fully-distributed configuration to fully test HBase and to use it in real-world scenarios. In a distributed configuration, the cluster contains multiple nodes, each of which runs one or more HBase daemon. These include primary and backup Master instances, multiple ZooKeeper nodes, and multiple RegionServer nodes.

This advanced quickstart adds two more nodes to your cluster. The architecture will be as follows:

| Node Name          | Master | ZooKeeper | RegionServer |
| ------------------ | ------ | --------- | ------------ |
| node-a.example.com | yes    | yes       | no           |
| node-b.example.com | backup | yes       | yes          |
| node-c.example.com | no     | yes       | yes          |

This quickstart assumes that each node is a virtual machine and that they are all on the same network. It builds upon the previous quickstart, [Pseudo-Distributed Local Install](#quickstart_pseudo), assuming that the system you configured in that procedure is now `node-a`. Stop HBase on `node-a` before continuing.

> Be sure that all the nodes have full access to communicate, and that no firewall rules are in place which could prevent them from talking to each other. If you see any errors like `no route to host`, check your firewall.

Procedure: Configure Passwordless SSH Access

`node-a` needs to be able to log into `node-b` and `node-c` (and to itself) in order to start the daemons. The easiest way to accomplish this is to use the same username on all hosts, and configure password-less SSH login from `node-a` to each of the others.

1. On `node-a`, generate a key pair.

   While logged in as the user who will run HBase, generate a SSH key pair, using the following command:

   ```
   $ ssh-keygen -t rsa
   ```

   If the command succeeds, the location of the key pair is printed to standard output. The default name of the public key is _id_rsa.pub_.

2. Create the directory that will hold the shared keys on the other nodes.

   On `node-b` and `node-c`, log in as the HBase user and create a _.ssh/_ directory in the user’s home directory, if it does not already exist. If it already exists, be aware that it may already contain other keys.

3. Copy the public key to the other nodes.

   Securely copy the public key from `node-a` to each of the nodes, by using the `scp` or some other secure means. On each of the other nodes, create a new file called _.ssh/authorized_keys_ _if it does not already exist_, and append the contents of the _id_rsa.pub_ file to the end of it. Note that you also need to do this for `node-a` itself.

   ```
   $ cat id_rsa.pub >> ~/.ssh/authorized_keys
   ```

4. Test password-less login.

   If you performed the procedure correctly, you should not be prompted for a password when you SSH from `node-a` to either of the other nodes using the same username.

5. Since `node-b` will run a backup Master, repeat the procedure above, substituting `node-b` everywhere you see `node-a`. Be sure not to overwrite your existing _.ssh/authorized_keys_ files, but concatenate the new key onto the existing file using the `>>` operator rather than the `>` operator.

Procedure: Prepare `node-a`

`node-a` will run your primary master and ZooKeeper processes, but no RegionServers. Stop the RegionServer from starting on `node-a`.

1. Edit _conf/regionservers_ and remove the line which contains `localhost`. Add lines with the hostnames or IP addresses for `node-b` and `node-c`.

   Even if you did want to run a RegionServer on `node-a`, you should refer to it by the hostname the other servers would use to communicate with it. In this case, that would be `node-a.example.com`. This enables you to distribute the configuration to each node of your cluster any hostname conflicts. Save the file.

2. Configure HBase to use `node-b` as a backup master.

   Create a new file in _conf/_ called _backup-masters_, and add a new line to it with the hostname for `node-b`. In this demonstration, the hostname is `node-b.example.com`.

3. Configure ZooKeeper

   In reality, you should carefully consider your ZooKeeper configuration. You can find out more about configuring ZooKeeper in [zookeeper](#zookeeper) section. This configuration will direct HBase to start and manage a ZooKeeper instance on each node of the cluster.

   On `node-a`, edit _conf/hbase-site.xml_ and add the following properties.

   ```
   <property>
     <name>hbase.zookeeper.quorum</name>
     <value>node-a.example.com,node-b.example.com,node-c.example.com</value>
   </property>
   <property>
     <name>hbase.zookeeper.property.dataDir</name>
     <value>/usr/local/zookeeper</value>
   </property>
   ```

4. Everywhere in your configuration that you have referred to `node-a` as `localhost`, change the reference to point to the hostname that the other nodes will use to refer to `node-a`. In these examples, the hostname is `node-a.example.com`.

Procedure: Prepare `node-b` and `node-c`

`node-b` will run a backup master server and a ZooKeeper instance.

1. Download and unpack HBase.

   Download and unpack HBase to `node-b`, just as you did for the standalone and pseudo-distributed quickstarts.

2. Copy the configuration files from `node-a` to `node-b`.and `node-c`.

   Each node of your cluster needs to have the same configuration information. Copy the contents of the _conf/_ directory to the _conf/_ directory on `node-b` and `node-c`.

Procedure: Start and Test Your Cluster

1. Be sure HBase is not running on any node.

   If you forgot to stop HBase from previous testing, you will have errors. Check to see whether HBase is running on any of your nodes by using the `jps` command. Look for the processes `HMaster`, `HRegionServer`, and `HQuorumPeer`. If they exist, kill them.

2. Start the cluster.

   On `node-a`, issue the `start-hbase.sh` command. Your output will be similar to that below.

   ```
   $ bin/start-hbase.sh
   node-c.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-c.example.com.out
   node-a.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-a.example.com.out
   node-b.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-b.example.com.out
   starting master, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-master-node-a.example.com.out
   node-c.example.com: starting regionserver, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-regionserver-node-c.example.com.out
   node-b.example.com: starting regionserver, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-regionserver-node-b.example.com.out
   node-b.example.com: starting master, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-master-nodeb.example.com.out
   ```

   ZooKeeper starts first, followed by the master, then the RegionServers, and finally the backup masters.

3. Verify that the processes are running.

   On each node of the cluster, run the `jps` command and verify that the correct processes are running on each server. You may see additional Java processes running on your servers as well, if they are used for other purposes.

   `node-a` `jps` Output

   ```
   $ jps
   20355 Jps
   20071 HQuorumPeer
   20137 HMaster
   ```

   `node-b` `jps` Output

   ```
   $ jps
   15930 HRegionServer
   16194 Jps
   15838 HQuorumPeer
   16010 HMaster
   ```

   `node-c` `jps` Output

   ```
   $ jps
   13901 Jps
   13639 HQuorumPeer
   13737 HRegionServer
   ```

   > ZooKeeper Process Name
   >
   > The `HQuorumPeer` process is a ZooKeeper instance which is controlled and started by HBase. If you use ZooKeeper this way, it is limited to one instance per cluster node and is appropriate for testing only. If ZooKeeper is run outside of HBase, the process is called `QuorumPeer`. For more about ZooKeeper configuration, including using an external ZooKeeper instance with HBase, see [zookeeper](#zookeeper) section.

4. Browse to the Web UI.

   > Web UI Port ChangesWeb UI Port Changes

   In HBase newer than 0.98.x, the HTTP ports used by the HBase Web UI changed from 60010 for the Master and 60030 for each RegionServer to 16010 for the Master and 16030 for the RegionServer.

   If everything is set up correctly, you should be able to connect to the UI for the Master `[http://node-a.example.com:16010/](http://node-a.example.com:16010/)` or the secondary master at `[http://node-b.example.com:16010/](http://node-b.example.com:16010/)` using a web browser. If you can connect via `localhost` but not from another host, check your firewall rules. You can see the web UI for each of the RegionServers at port 16030 of their IP addresses, or by clicking their links in the web UI for the Master.

5. Test what happens when nodes or services disappear.

   With a three-node cluster you have configured, things will not be very resilient. You can still test the behavior of the primary Master or a RegionServer by killing the associated processes and watching the logs.

### 2.5\. Where to go next

The next chapter, [configuration](#configuration), gives more information about the different HBase run modes, system requirements for running HBase, and critical configuration areas for setting up a distributed HBase cluster.