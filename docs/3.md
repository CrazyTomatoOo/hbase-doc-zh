

# HBase升级

当你想要升级时，你不能跳过主要版本。当你从版本0.98.x到 2.x时，你必须首先升级到1.2.x再从1.2.x升级到 2.x。

回顾 [Apache HBase 配置](#configuration)章节，还有 [Hadoop](https://hadoop.apache.org)，并熟悉 [支持和测试](#hbase_supported_tested_definitions).

## 11\. HBase版本号和兼容性


### 11.1\. 期望语义版本控制

从版本1.0.0开始，HBase采用 [Semantic Versioning](http://semver.org/)作为版本控制。

对于给定的版本号 MAJOR.MINOR.PATCH，增加如下内容：

MINOR 版本，当您以向后兼容的方式添加功能时
PATCH 版本，当您进行向后兼容的错误修复时
预发布和构建元数据的其他标签可作为MAJOR.MINOR.PATCH格式的扩展。

*   MAJOR 版本，当你进行不兼容的 API 更改时

*   MINOR 版本，当您以向后兼容的方式添加功能时

*  PATCH 版本，当您进行向后兼容的错误修复时

*   预发布和构建元数据的其他标签可作为MAJOR.MINOR.PATCH格式的扩展。

兼容性维度

除了通常的 API 版本考虑之外，HBase 还有其他需要考虑的兼容性维度。


Client-Server 线协议兼容性：


*   允许不同步更新客户端和服务器。

*   我们只能允许先升级服务器。也就是说，服务器将向后兼容旧客户端，这样新的 API 就可以使用。

*   示例：用户应该能够使用旧客户端连接到升级的群集。


Server-Server 协议兼容性：


*   不同版本的服务器可以共存于同一个群集中。

*   服务器之间的有线协议是兼容的。

*   分布式任务的工作人员（如复制和日志拆分）可以共存于同一个群集中。

*   相关协议（如使用ZK进行协调）也不会改变。


*   示例：用户可以执行滚动升级。


文件格式兼容性：


*   支持文件格式向前和向后兼容


*   示例：文件、ZK 编码、目录布局自动升级为 HBase 升级的一部分。用户可以降级到旧版本，并且一切都将继续工作。

客户端 API 兼容性：


*   允许更改或删除现有的客户端 API。


*   在我们更改/删除主要版本之前，API 需要被弃用。


*   修补程序（patch）版本中提供的 API 将在所有后续修补程序版本中提供。但是，可能会添加新的 API，这些 API 在以前的修补程序版本中将不可用。


*   修补程序版本中引入的新 API 只能以源代码兼容的方式添加：即实现公共 API 的代码将继续编译<sup class="footnote">[[1](#_footnote_1 "View footnote.")]</sup>:。示例：使用新废用的 API 的用户不需要使用 HBase API 调用修改应用程序代码，直到下一个主要版本。

    *   示例：在下一个主要版本之前，使用新弃用的API的用户不需要修改应用程序的HBase API调用代码。

客户端二进制兼容性：

*   写入给定修补程序版本中提供的 API 的客户端代码可以运行不变（不需要重新编译），以抵补新的 jar 后续补丁版本。


*   写入给定修补程序版本中提供的 API 的客户端代码可能无法针对早期修补程序版本中的旧 jar 运行。示例：旧编译的客户端代码将在 jar 中保持不变。

    *   示例：旧编译的客户端代码将在 jar 中保持不变。

*   如果客户端实现 HBase 接口，则可能需要重新编译升级到较新的次要（minor）版本。


服务器端有限的 API 兼容性（取自 Hadoop）：

*   内部API被标记为“稳定（Stable）”，“正在发展（Evolving）”或“不稳定（Unstable）”。

*   这意味着协处理器和插件（可插入类，包括复制）的二进制兼容性，只要这些只使用标记的接口/类。

*   例如：旧编译的协处理器，过滤器或插件代码将在新 jar 中保持不变。


相关性兼容性：


*   HBase 的升级除Apache Hadoop外，不需要依赖项目的兼容升级，包括运行 Java 时。


*   HBase 的升级不需要依赖项目的兼容升级，包括Java 。

*   示例：将HBase升级到支持_依赖兼容性_的版本不需要升级Apache ZooKeeper服务。

*   示例：示例：如果当前版本的HBase支持在JDK 8上运行，则升级到支持_依赖兼容性_的版本也将在JDK 8上运行。

> Hadoop 版本
>
> 之前，我们尝试维护基础Hadoop服务的依赖兼容性，但在过去几年中，这已经证明是站不住脚的。 虽然HBase项目试图维持对旧版本Hadoop的支持，但我们删除了次要版本的“受支持”指示符。 此外，Hadoop项目有自己的一组兼容性指南，这意味着在某些情况下，会破坏指南，也就是必须更新到较新的受支持的次要版本。

操作兼容性：


*   度量标准的更改

*   服务的行为变化

*   通过 `/jmx/` 端点公开的 JMX API


概要

*   修补程序（patch）升级是一种直接替代方案。任何不是 Java 二进制和源代码兼容的更改都将不被允许<sup class="footnote">[[2](#_footnote_2 "View footnote.")]</sup>。在修补程序版本中降级版本可能不兼容。

*   次要（minor）升级不需要修改应用程序/客户端代码。理想情况下，这将是一个直接替换，但如果使用新的 jar，则客户端代码，协处理器，过滤器等可能必须重新编译。


*   主要（major）升级允许 HBase 做出重大改变。

|  | Major | Minor | Patch |
| --- | --- | --- | --- |
| 客户端 - 服务器线路兼容性 | N | Y | Y |
| 服务器 - 服务器兼容性 | N | Y | Y |
| 文件格式兼容性 | N <sup class="footnote">[[4](#_footnote_4 "View footnote.")]</sup> | Y | Y |
| 客户端API兼容性 | N | Y | Y |
| 客户端二进制兼容性 | N | N | Y |
| 服务器端有限的API兼容性 |
| 稳定性（Stable） | N | Y | Y |
| 发展性（Evolving） | N | N | Y |
| 不稳定性（Unstable） | N | N | N |
| 相关性兼容性 | N | Y | Y |
| 操作兼容性 | N | N | Y |

#### 11.1.1\. HBase API 

HBase 有很多 API 要点，但对于上面的兼容性矩阵，我们区分了Client API（客户端 API），Limited Private API（有限的私有 API）和 Private API（私有 API）。HBase 使用 [Apache Yetus Audience Annotations](https://yetus.apache.org/documentation/0.5.0/interface-classification/) 来定义稳定性

*   InterfaceAudience ([javadocs](https://yetus.apache.org/documentation/0.5.0/audience-annotations-apidocs/org/apache/yetus/audience/InterfaceAudience.html)): 捕捉预期的受众，可能的值包括：

    *   Public：对于最终用户和外部项目是安全的；

    *   LimitedPrivate：用于我们期望可插入的内部组件，如协处理器；  

    *   Private：严格用于 HBase 自身内部定义为 IA 的类中，Private 可以用作声明 `IA.LimitedPrivate` 接口的参数或返回值。将`IA.Private`对象视为不透明；不要尝试直接访问其方法或字段。

*   InterfaceStability ([javadocs](https://yetus.apache.org/documentation/0.5.0/audience-annotations-apidocs/org/apache/yetus/audience/InterfaceStability.html)): 描述允许接口更改的类型。可能的值包括：

    *   Stable：接口是固定的，预计不会改变；

    *   Evolving：界面可能会在未来的minor 版本中改变；

    *   Unstable：界面可能随时更改

请记住 HBase 项目中 `InterfaceAudience` 注释和 `InterfaceStability` 注释之间的以下相互作用：

*   `IA.Public` 类本质上是稳定的，并坚持我们有关升级类型（主要，次要或修补程序）的稳定性保证。

*   `IA.LimitedPrivate` 类应始终使用给定的 `InterfaceStability` 值的其中一个进行注释。如果他们不是，你应该假定他们是 `IS.Unstable`。

*   `IA.Private` 类应该被认为是隐含不稳定的，不能保证发布之间的稳定性。

HBase Client API

HBase 客户端 API 由所有标记有 InterfaceAudience.Public 接口的类或方法组成。hbase-client 和依赖模块中的所有主类都有InterfaceAudience.Public，InterfaceAudience.LimitedPrivate或InterfaceAudience.Private标记。并非所有其他模块（hbase-server等）中的类都有标记。如果一个类没有使用上述中的一个注释，则它被认为是一个InterfaceAudience.Private类。


HBase LimitedPrivate API

LimitedPrivate 注释为接口附带了一组目标使用者。这些使用者是协处理器，phoenix，复制端点实现等。此时，HBase 只能保证修补程序版本之间的这些接口的源和二进制兼容性。


HBase Private API

所有使用InterfaceAudience.Private注释的类或没有注释的所有类仅在HBase内部使用。接口和方法签名可以随时改变。如果您依赖于标记为Private的特定界面，则应打开jira以建议将界面更改为Public或LimitedPrivate，或者为此目的公开的接口。


二进制兼容性：

当我们说两个 HBase 版本是兼容的时，我们的意思是这些版本是线（wire）和二进制兼容的。兼容的HBase版本意味着客户可以与兼容但不同版本的服务器通话。这也意味着你可以换出一个版本的 jar，并用另一个兼容版本的 jar 替换它们，所有的 jar 都可以工作。除非另有说明，否则 HBase 主要的版本都是二进制兼容的。您可以安全地在二进制兼容版本之间进行滚动升级。例如从1.2.4到 1.2.6\.详见:[Does compatibility between versions also mean binary compatibility?] 在HBase论坛的讨论。

### 11.2\. 滚动升级

滚动升级是您一次更新服务器群集中的服务器的过程。如果它们是二进制或线路兼容的，则可以跨 HBase版本进行滚动升级。详见：[Rolling Upgrade Between Versions that are Binary/Wire Compatible](#hbase.rolling.restart) 粗略地说，滚动升级是正常地停止每台服务器，更新软件，然后重新启动。您可以为集群中的每个服务器执行此操作。通常先升级 Master，然后再升级 RegionServers。 查看 [Rolling Restart](#rolling) 

例如，下面的 HBase 是 symlinked 实际的 HBase 安装。在升级之前，在群集上运行滚动重启之前，我们将 symlink 更改为指向新的 HBase 软件版本，然后运行：


```
$ HADOOP_HOME=~/hadoop-2.6.0-CRC-SNAPSHOT ~/hbase/bin/rolling-restart.sh --config ~/conf_hbase
```

滚动重新启动脚本将首先正常停止并重新启动主服务器，然后依次重新启动每个 RegionServer。由于 symlink 被更改，所以重新启动时，服务器将使用新的HBase 版本。随着滚动升级的进行，检查日志中是否有错误。 

在兼容二进制/Wire的版本之间进行滚动升级：

除非另有说明，否则 HBase 指向的版本是二进制兼容的。您可以在 HBase 主要版本之间进行[滚动升级](#hbase.rolling.upgrade)。例如，您可以通过在集群中进行滚动升级，使用0.94.6二进制文件替换0.94.5二进制文件，从而从 0.94.5 转到 0.94.6。

在次要（minor）版本中，我们调用的版本是有线/协议兼容的，在这种情况下，也可以执行[滚动升级](#hbase.rolling.upgrade)。

## 12\. 版本恢复

当你在试着升级 HBase 的时候，你可能会遇到升级失败的问题，并且想要将其恢复成之前的版本。本节就介绍如何执行_回滚_以将 HBase 恢复为到较早的版本。请注意，这应该只在主要版本和一些次要版本之间需要。您应该始终能够在相同次要版本的 HBase Patch 版本之间进行_降级_。这些说明可能要求您在开始升级过程之前注意相关的事项，因此请务必事先阅读本节。 

### 12.1\. 警告

回滚与降级

本节介绍如何对 HBase 次要版本和主要版本之间的升级执行回滚。在本文档中，回滚指的是采取升级后的集群并将其恢复到旧版本的过程，同时_丢失升级后发生的所有更改_。相比之下，群集降级会将升级后的群集恢复到旧版本，同时保留升级后写入的任何数据。我们目前仅提供回滚 HBase 集群的说明。此外，只有在执行升级之前遵循这些说明，回滚才有效。 

当这些指令谈论回滚与降级的先决条件群集服务（即HDFS）时，您应该将服务版本与退化的降级案例视为相同。


复制

除非您正在执行全部服务回滚，否则 HBase 群集将会丢失任何配置的对等 HBase 复制。如果您的集群配置为 HBase 复制，那么在按照这些说明[Managing and Configuring Cluster Replication](#hbase.replication.management)进行操作之前，您应该记录所有复制节点。执行回滚之后，您应该将每个记录的对等点添加回群集。另外要注意，自升级后写入群集的数据可能已经或可能未被复制到任何对等方。 

数据位置

除非您正在执行全部服务回滚，否则通过回滚过程可能会破坏Region Server的所有局部位置。在群集有时间通过紧凑排列恢复数据位置之前，您应该期望性能的降级。或者，您可以强制压缩来加速此过程，但要以生成群集负载为代价。


可配置的位置

以下说明假设 HBase 数据目录和 HBase znode 的默认位置。这两个位置都是可配置的，您应该在继续操作之前验证群集中使用的值。如果您有不同的值，只需将默认值替换为在配置中找到的 HBase 数据目录，它是通过密钥 "HBase" (rootdir) 配置的，并且具有默认的 "/HBase"。* HBase znode通过密钥'zookeeper.znode.parent'进行配置，默认值为'/ hbase'。 

### 12.2\. 所有服务回滚

如果您要执行 HDFS 和 ZooKeeper 服务的回滚，那么 HBase 的数据将在此过程中回滚。


要求

*   能够回滚 HDFS 和 ZooKeeper

升级前

在升级前不需要额外的步骤。作为一项额外的预防措施，您可能希望使用 distcp 将 HBase 数据备份到要升级的群集之外。为此，请本节内容中的按照“HDFS降级后回滚”的“升级前”部分中的步骤操作，但它是复制到另一个 HDFS 实例，而不是在同一实例中。 

执行回滚

1.  停止 HBase

2.  执行 HDFS 和 ZooKeeper 的回滚（HBase 应该保持停止状态）


3.  将安装的 HBase 版本更改为以前的版本

4.  启动 HBase

5.  验证 HBase 内容 - 使用 HBase shell 列出表格并扫描一些已知值。


### 12.3\. HDFS 回滚和 ZooKeeper 降级后回滚


如果您将回滚 HDFS，但通过 ZooKeeper 降级，那么 HBase 将处于不一致的状态。在完成此过程之前，您必须确保集群未启动。


要求

*   能够回滚 HDFS

*   能够降级 ZooKeeper


升级前


在升级前不需要额外的步骤。作为一种额外的预防措施，您可能希望使用 distcp 将 HBase 数据备份到要升级的群集之外。为此，请本节内容中的按照“HDFS降级后回滚”的“升级前”部分中的步骤操作，但它将复制到另一个HDFS实例，而不是在同一实例中。


执行回滚


1.  停止 HBase


2.  执行 HDFS 回滚和 ZooKeeper 降级（HBase 应该保持停止状态）


3.  将安装的 HBase 版本更改为以前的版本


4.  清除与 HBase 相关的 ZooKeeper 信息。警告：此步骤将永久销毁所有复制对等点。


    清理 ZooKeeper 中的 HBase 信息

    ```
    [hpnewton@gateway_node.example.com ~]$ zookeeper-client -server zookeeper1.example.com:2181,zookeeper2.example.com:2181,zookeeper3.example.com:2181
    Welcome to ZooKeeper!
    JLine support is disabled
    rmr /hbase
    quit
    Quitting...
    ```

5.  启动 HBase


6.  验证 HBase 内容 - 使用 HBase shell 列出表格并扫描一些已知值。


### 12.4\. HDFS 降级后回滚

如果您要执行 HDFS 降级，则无论ZooKeeper是否通过回滚、降级或重新安装，您都需要遵循这些指示信息。 

要求

*   可以降级 HDFS

*   升级前群集必须能够运行 MapReduce 作业

*   HDFS 超级用户访问

*   在 HDFS 中至少有两个 HBase 数据目录的副本空间可以降级 HDFS

升级前


在开始升级过程之前，您必须对 HBase 的支持数据进行完整备份。以下说明介绍了在当前HDFS实例中备份数据的过程。或者，您可以使用 distcp 命令将数据复制到另一个 HDFS 群集。 

1.  停止 HBase 群集


2.  将 HBase 数据目录复制到备份位置, 方法[distcp command](https://hadoop.apache.org/docs/current/hadoop-distcp/DistCp.html)是使用 distcp 命令作为 HDFS 超级用户 (下面显示在启用安全的群集上)

    使用distcp备份HBase数据目录：

    ```
    [hpnewton@gateway_node.example.com ~]$ kinit -k -t hdfs.keytab hdfs@EXAMPLE.COM
    [hpnewton@gateway_node.example.com ~]$ hadoop distcp /hbase /hbase-pre-upgrade-backup
    ```

3.  Distcp 将启动一个 mapreduce 作业来处理以分布式方式复制文件。检查 distcp 命令的输出，以确保此作业成功完成。


执行回滚


1.  停止 HBase

2.  执行 HDFS 的降级和 ZooKeeper 的降级/回滚（HBase 应该保持停止状态）

3.  将安装的 HBase 版本更改为以前的版本

4.  将 HBase 数据目录从升级前恢复为 HDFS 超级用户 (如下所示在启用安全的群集上)。如果您将数据备份到另一个 HDFS 群集而不是本地，则需要使用distcp 命令将其复制回当前的 HDFS 群集。
    恢复 HBase 数据目录：

    ```
    [hpnewton@gateway_node.example.com ~]$ kinit -k -t hdfs.keytab hdfs@EXAMPLE.COM
    [hpnewton@gateway_node.example.com ~]$ hdfs dfs -mv /hbase /hbase-upgrade-rollback
    [hpnewton@gateway_node.example.com ~]$ hdfs dfs -mv /hbase-pre-upgrade-backup /hbase
    ```

5.  清除与 HBase 相关的 ZooKeeper 信息。警告：此步骤将永久销毁所有复制对等点。


    清理 ZooKeeper 中的 HBase 信息：


    ```
    [hpnewton@gateway_node.example.com ~]$ zookeeper-client -server zookeeper1.example.com:2181,zookeeper2.example.com:2181,zookeeper3.example.com:2181
    Welcome to ZooKeeper!
    JLine support is disabled
    rmr /hbase
    quit
    Quitting...
    ```

6.  启动 HBase

7.  验证 HBase 内容 - 使用 HBase shell 列出表格并扫描一些已知值。

## 13\. HBase升级路径


### 13.1\. 从 1.x 升级到 2.x

在本节中，先前稳定的HBase版本相比所发生的重大变化，一定要仔细阅读，然后再进行升级。以免发生意外。

#### 13.1.1\. 变化通告

首先，我们将介绍升级到HBase 2.0+时可能遇到的部署/操作更改。之后，我们将告知下游应用程序的更改。请注意，协处理器包含在操作部分中。另外请注意，本节并不旨在传达您可能感兴趣的新功能的信息。有关更改的完整摘要，请参阅您计划升级到的版本的源发布工件中的changes.txt文件。


更新到HBase 2.0+的基本最低先决条件

如之前章节所述 [Basic Prerequisites](#basic.prerequisites), HBase 2.0+ 需要依赖Java 8 和 Hadoop 2.6\. HBase社区建议在升级您的HBase版本之前，确保您已经完成了任何必要的先决条件升级。

HBCK 一定要匹配HBase版本

 **一定不要**在HBase 2.0+ 集群上使用 HBase 1.x 版本的 HBCK。 HBCK是严格绑定 HBase版本的。 对hbase 2.0+集群使用早期版本的hbck工具将以不可恢复的方式破坏性地改变集群。

从HBase 2.0开始， HBCK (也叫做_HBCK1_ 或 _hbck1_)是一个只读工具，可以报告某些非公共系统内部的状态。您不应该依赖这些内部构件的格式和内容来保持HBase版本之间的一致性。

替代品详见： [HBase `HBCK2`](#HBCK2) 和 [Apache HBase Operational Management](#ops_mgt).

配置设置不再位于HBase 2.0+

下列配置设置不再适用或不可用。有关详细信息，请参阅详细的发行说明。


*   hbase.config.read.zookeeper.config (查看 [ZooKeeper configs no longer read from zoo.cfg](#upgrade2.0.zkconfig) )

*   hbase.zookeeper.useMulti (HBase现在使用ZK’s multi functionality)
    
*   hbase.rpc.client.threads.max

*   hbase.rpc.client.nativetransport

*   hbase.fs.tmp.dir

*   hbase.bucketcache.combinedcache.enabled

*   hbase.bucketcache.ioengine 不再支持 'heap' 值.

*   hbase.bulkload.staging.dir

*   hbase.balancer.tablesOnMaster 严格地说，它并没有被删除，但它的意义已经发生了根本性的改变，用户不应该设置它。详见： ["Master hosting regions" feature broken and unsupported](#upgrade2.0.regions.on.master) 

*   hbase.master.distributed.log.replay 详见： ["Distributed Log Replay" feature broken and removed](#upgrade2.0.distributed.log.replay) 

*   hbase.regionserver.disallow.writes.when.recovering 详见： ["Distributed Log Replay" feature broken and removed](#upgrade2.0.distributed.log.replay) 

*   hbase.regionserver.wal.logreplay.batch.size 详见： ["Distributed Log Replay" feature broken and removed](#upgrade2.0.distributed.log.replay) 

*   hbase.master.catalog.timeout

*   hbase.regionserver.catalog.timeout

*   hbase.metrics.exposeOperationTimes

*   hbase.metrics.showTableName

*   hbase.online.schema.update.enable (HBase 不再支持)

*   hbase.thrift.htablepool.size.max

在HBase 2.0+重命名的配置属性

已重命名以下属性。在运行时设置旧属性将失败。

| 旧名称 | 新名称 |
| --- | --- |
| hbase.rpc.server.nativetransport | hbase.netty.nativetransport |
| hbase.netty.rpc.server.worker.count | hbase.netty.worker.count |
| hbase.hfile.compactions.discharger.interval | hbase.hfile.compaction.discharger.interval |
| hbase.hregion.percolumnfamilyflush.size.lower.bound | hbase.hregion.percolumnfamilyflush.size.lower.bound.min |

在HBase 2.0+中具有不同默认值的配置

以下配置设置更改了它们的默认值。在适用的情况下，将给出hbase 1.2行为的设置值。


*   hbase.security.authorization 默认 false. 之前版本的default是true

*   hbase.client.retries.number 现在默认10\. 之前默认 35\.建议下游用户使用 [Timeout settings](#config_timeouts) 所述的客户端超时。

*   hbase.client.serverside.retries.multiplier 现在默认3\. 之前默认 10\.建议下游用户使用 [Timeout settings](#config_timeouts) 所述的客户端超时。

*   hbase.master.fileSplitTimeout 默认10分钟，之前是30秒

*   hbase.regionserver.logroll.multiplier默认 0.5\之前 0.95\. 此更改与下面的块大小加倍有关。结合起来，这两个配置更改应该使WAL的大小与HBase-1.x中的大小大致相同，但是小块的发生率应该更低，因为在达到块大小阈值之前，我们无法滚动WAL。
详见： [HBASE-19148](https://issues.apache.org/jira/browse/HBASE-19148) 

*   hbase.regionserver.hlog.blocksize defaults to 2x the HDFS default block size for the WAL dir. Previously it was equal to the HDFS default block size for the WAL dir.

*   hbase.client.start.log.errors.counter changed to 5\. Previously it was 9.

*   hbase.ipc.server.callqueue.type changed to 'fifo'. In HBase versions 1.0 - 1.2 it was 'deadline'. In prior and later 1.x versions it already defaults to 'fifo'.

*   hbase.hregion.memstore.chunkpool.maxsize is 1.0 by default. Previously it was 0.0\. Effectively, this means previously we would not use a chunk pool when our memstore is onheap and now we will. See the section [Long GC pauses](#gcpause) for more infromation about the MSLAB chunk pool.

*   hbase.master.cleaner.interval is now set to 10 minutes. Previously it was 1 minute.

*   hbase.master.procedure.threads will now default to 1/4 of the number of available CPUs, but not less than 16 threads. Previously it would be number of threads equal to number of CPUs.

*   hbase.hstore.blockingStoreFiles is now 16\. Previously it was 10.

*   hbase.http.max.threads is now 16\. Previously it was 10.

*   hbase.client.max.perserver.tasks is now 2\. Previously it was 5.

*   hbase.normalizer.period is now 5 minutes. Previously it was 30 minutes.

*   hbase.regionserver.region.split.policy is now SteppingSplitPolicy. Previously it was IncreasingToUpperBoundRegionSplitPolicy.

*   replication.source.ratio is now 0.5\. Previously it was 0.1.

"Master hosting regions" feature broken and unsupported

The feature "Master acts as region server" and associated follow-on work available in HBase 1.y is non-functional in HBase 2.y and should not be used in a production setting due to deadlock on Master initialization. Downstream users are advised to treat related configuration settings as experimental and the feature as inappropriate for production settings.

A brief summary of related changes:

*   Master no longer carries regions by default

*   hbase.balancer.tablesOnMaster is a boolean, default false (if it holds an HBase 1.x list of tables, will default to false)

*   hbase.balancer.tablesOnMaster.systemTablesOnly is boolean to keep user tables off master. default false

*   those wishing to replicate old list-of-servers config should deploy a stand-alone RegionServer process and then rely on Region Server Groups

"Distributed Log Replay" feature broken and removed

The Distributed Log Replay feature was broken and has been removed from HBase 2.y+. As a consequence all related configs, metrics, RPC fields, and logging have also been removed. Note that this feature was found to be unreliable in the run up to HBase 1.0, defaulted to being unused, and was effectively removed in HBase 1.2.0 when we started ignoring the config that turns it on ([HBASE-14465](https://issues.apache.org/jira/browse/HBASE-14465)). If you are currently using the feature, be sure to perform a clean shutdown, ensure all DLR work is complete, and disable the feature prior to upgrading.

_prefix-tree_ encoding removed

The prefix-tree encoding was removed from HBase 2.0.0 ([HBASE-19179](https://issues.apache.org/jira/browse/HBASE-19179)). It was (late!) deprecated in hbase-1.2.7, hbase-1.4.0, and hbase-1.3.2.

This feature was removed because it as not being actively maintained. If interested in reviving this sweet facility which improved random read latencies at the expensive of slowed writes, write the HBase developers list at _dev at hbase dot apache dot org_.

The prefix-tree encoding needs to be removed from all tables before upgrading to HBase 2.0+. To do that first you need to change the encoding from PREFIX_TREE to something else that is supported in HBase 2.0. After that you have to major compact the tables that were using PREFIX_TREE encoding before. To check which column families are using incompatible data block encoding you can use [Pre-Upgrade Validator](#ops.pre-upgrade).

Changed metrics

The following metrics have changed names:

*   Metrics previously published under the name "AssignmentManger" [sic] are now published under the name "AssignmentManager"

The following metrics have changed their meaning:

*   The metric 'blockCacheEvictionCount' published on a per-region server basis no longer includes blocks removed from the cache due to the invalidation of the hfiles they are from (e.g. via compaction).

*   The metric 'totalRequestCount' increments once per request; previously it incremented by the number of `Actions` carried in the request; e.g. if a request was a `multi` made of four Gets and two Puts, we’d increment 'totalRequestCount' by six; now we increment by one regardless. Expect to see lower values for this metric in hbase-2.0.0.

*   The 'readRequestCount' now counts reads that return a non-empty row where in older hbases, we’d increment 'readRequestCount' whether a Result or not. This change will flatten the profile of the read-requests graphs if requests for non-existent rows. A YCSB read-heavy workload can do this dependent on how the database was loaded.

The following metrics have been removed:

*   Metrics related to the Distributed Log Replay feature are no longer present. They were previsouly found in the region server context under the name 'replay'. See the section ["Distributed Log Replay" feature broken and removed](#upgrade2.0.distributed.log.replay) for details.

The following metrics have been added:

*   'totalRowActionRequestCount' is a count of region row actions summing reads and writes.

Changed logging

HBase-2.0.0 now uses [slf4j](https://www.slf4j.org/) as its logging frontend. Prevously, we used [log4j (1.2)](http://logging.apache.org/log4j/1.2/). For most the transition should be seamless; slf4j does a good job interpreting _log4j.properties_ logging configuration files such that you should not notice any difference in your log system emissions.

That said, your _log4j.properties_ may need freshening. See [HBASE-20351](https://issues.apache.org/jira/browse/HBASE-20351) for example, where a stale log configuration file manifest as netty configuration being dumped at DEBUG level as preamble on every shell command invocation.

ZooKeeper configs no longer read from zoo.cfg

HBase no longer optionally reads the 'zoo.cfg' file for ZooKeeper related configuration settings. If you previously relied on the 'hbase.config.read.zookeeper.config' config for this functionality, you should migrate any needed settings to the hbase-site.xml file while adding the prefix 'hbase.zookeeper.property.' to each property name.

Changes in permissions

The following permission related changes either altered semantics or defaults:

*   Permissions granted to a user now merge with existing permissions for that user, rather than over-writing them. (see [the release note on HBASE-17472](https://issues.apache.org/jira/browse/HBASE-17472) for details)

*   Region Server Group commands (added in 1.4.0) now require admin privileges.

Most Admin APIs don’t work against an HBase 2.0+ cluster from pre-HBase 2.0 clients

A number of admin commands are known to not work when used from a pre-HBase 2.0 client. This includes an HBase Shell that has the library jars from pre-HBase 2.0\. You will need to plan for an outage of use of admin APIs and commands until you can also update to the needed client version.

The following client operations do not work against HBase 2.0+ cluster when executed from a pre-HBase 2.0 client:

*   list_procedures

*   split

*   merge_region

*   list_quotas

*   enable_table_replication

*   disable_table_replication

*   Snapshot related commands

Deprecated in 1.0 admin commands have been removed.

The following commands that were deprecated in 1.0 have been removed. Where applicable the replacement command is listed.

*   The 'hlog' command has been removed. Downstream users should rely on the 'wal' command instead.

Region Server memory consumption changes.

Users upgrading from versions prior to HBase 1.4 should read the instructions in section [Region Server memory consumption changes.](#upgrade1.4.memory).

Additionally, HBase 2.0 has changed how memstore memory is tracked for flushing decisions. Previously, both the data size and overhead for storage were used to calculate utilization against the flush threashold. Now, only data size is used to make these per-region decisions. Globally the addition of the storage overhead is used to make decisions about forced flushes.

Web UI for splitting and merging operate on row prefixes

Previously, the Web UI included functionality on table status pages to merge or split based on an encoded region name. In HBase 2.0, instead this functionality works by taking a row prefix.

Special upgrading for Replication users from pre-HBase 1.4

User running versions of HBase prior to the 1.4.0 release that make use of replication should be sure to read the instructions in the section [Replication peer’s TableCFs config](#upgrade1.4.replication).

HBase shell changes

The HBase shell command relies on a bundled JRuby instance. This bundled JRuby been updated from version 1.6.8 to version 9.1.10.0\. The represents a change from Ruby 1.8 to Ruby 2.3.3, which introduces non-compatible language changes for user scripts.

The HBase shell command now ignores the '--return-values' flag that was present in early HBase 1.4 releases. Instead the shell always behaves as though that flag were passed. If you wish to avoid having expression results printed in the console you should alter your IRB configuration as noted in the section [_irbrc_](#irbrc).

Coprocessor APIs have changed in HBase 2.0+

All Coprocessor APIs have been refactored to improve supportability around binary API compatibility for future versions of HBase. If you or applications you rely on have custom HBase coprocessors, you should read [the release notes for HBASE-18169](https://issues.apache.org/jira/browse/HBASE-18169) for details of changes you will need to make prior to upgrading to HBase 2.0+.

For example, if you had a BaseRegionObserver in HBase 1.2 then at a minimum you will need to update it to implement both RegionObserver and RegionCoprocessor and add the method

```
...
  @Override
  public Optional<RegionObserver> getRegionObserver() {
    return Optional.of(this);
  }
...
```

HBase 2.0+ can no longer write HFile v2 files.

HBase has simplified our internal HFile handling. As a result, we can no longer write HFile versions earlier than the default of version 3\. Upgrading users should ensure that hfile.format.version is not set to 2 in hbase-site.xml before upgrading. Failing to do so will cause Region Server failure. HBase can still read HFiles written in the older version 2 format.

HBase 2.0+ can no longer read Sequence File based WAL file.

HBase can no longer read the deprecated WAL files written in the Apache Hadoop Sequence File format. The hbase.regionserver.hlog.reader.impl and hbase.regionserver.hlog.reader.impl configuration entries should be set to use the Protobuf based WAL reader / writer classes. This implementation has been the default since HBase 0.96, so legacy WAL files should not be a concern for most downstream users.

A clean cluster shutdown should ensure there are no WAL files. If you are unsure of a given WAL file’s format you can use the `hbase wal` command to parse files while the HBase cluster is offline. In HBase 2.0+, this command will not be able to read a Sequence File based WAL. For more information on the tool see the section [WALPrettyPrinter](#hlog_tool.prettyprint).

Change in behavior for filters

The Filter ReturnCode NEXT_ROW has been redefined as skipping to next row in current family, not to next row in all family. it’s more reasonable, because ReturnCode is a concept in store level, not in region level.

Downstream HBase 2.0+ users should use the shaded client

Downstream users are strongly urged to rely on the Maven coordinates org.apache.hbase:hbase-shaded-client for their runtime use. This artifact contains all the needed implementation details for talking to an HBase cluster while minimizing the number of third party dependencies exposed.

Note that this artifact exposes some classes in the org.apache.hadoop package space (e.g. o.a.h.configuration.Configuration) so that we can maintain source compatibility with our public API. Those classes are included so that they can be altered to use the same relocated third party dependencies as the rest of the HBase client code. In the event that you need to **also** use Hadoop in your code, you should ensure all Hadoop related jars precede the HBase client jar in your classpath.

Downstream HBase 2.0+ users of MapReduce must switch to new artifact

Downstream users of HBase’s integration for Apache Hadoop MapReduce must switch to relying on the org.apache.hbase:hbase-shaded-mapreduce module for their runtime use. Historically, downstream users relied on either the org.apache.hbase:hbase-server or org.apache.hbase:hbase-shaded-server artifacts for these classes. Both uses are no longer supported and in the vast majority of cases will fail at runtime.

Note that this artifact exposes some classes in the org.apache.hadoop package space (e.g. o.a.h.configuration.Configuration) so that we can maintain source compatibility with our public API. Those classes are included so that they can be altered to use the same relocated third party dependencies as the rest of the HBase client code. In the event that you need to **also** use Hadoop in your code, you should ensure all Hadoop related jars precede the HBase client jar in your classpath.

Significant changes to runtime classpath

A number of internal dependencies for HBase were updated or removed from the runtime classpath. Downstream client users who do not follow the guidance in [Downstream HBase 2.0+ users should use the shaded client](#upgrade2.0.shaded.client.preferred) will have to examine the set of dependencies Maven pulls in for impact. Downstream users of LimitedPrivate Coprocessor APIs will need to examine the runtime environment for impact. For details on our new handling of third party libraries that have historically been a problem with respect to harmonizing compatible runtime versions, see the reference guide section [The hbase-thirdparty dependency and shading/relocation](#thirdparty).

Multiple breaking changes to source and binary compatibility for client API

The Java client API for HBase has a number of changes that break both source and binary compatibility for details see the Compatibility Check Report for the release you’ll be upgrading to.

Tracing implementation changes

The backing implementation of HBase’s tracing features was updated from Apache HTrace 3 to HTrace 4, which includes several breaking changes. While HTrace 3 and 4 can coexist in the same runtime, they will not integrate with each other, leading to disjoint trace information.

The internal changes to HBase during this upgrade were sufficient for compilation, but it has not been confirmed that there are no regressions in tracing functionality. Please consider this feature expiremental for the immediate future.

If you previously relied on client side tracing integrated with HBase operations, it is recommended that you upgrade your usage to HTrace 4 as well.

HFile lose forward compatability

HFiles generated by 2.0.0, 2.0.1, 2.1.0 are not forward compatible to 1.4.6-, 1.3.2.1-, 1.2.6.1-, and other inactive releases. Why HFile lose compatability is hbase in new versions (2.0.0, 2.0.1, 2.1.0) use protobuf to serialize/deserialize TimeRangeTracker (TRT) while old versions use DataInput/DataOutput. To solve this, We have to put [HBASE-21012](https://jira.apache.org/jira/browse/HBASE-21012) to 2.x and put [HBASE-21013](https://jira.apache.org/jira/browse/HBASE-21013) in 1.x. For more information, please check [HBASE-21008](https://jira.apache.org/jira/browse/HBASE-21008).

Performance

You will likely see a change in the performance profile on upgrade to hbase-2.0.0 given read and write paths have undergone significant change. On release, writes may be slower with reads about the same or much better, dependent on context. Be prepared to spend time re-tuning (See [Apache HBase Performance Tuning](#performance)). Performance is also an area that is now under active review so look forward to improvement in coming releases (See [HBASE-20188 TESTING Performance](https://issues.apache.org/jira/browse/HBASE-20188)).

Integration Tests and Kerberos

Integration Tests (`IntegrationTests*`) used to rely on the Kerberos credential cache for authentication against secured clusters. This used to lead to tests failing due to authentication failures when the tickets in the credential cache expired. As of hbase-2.0.0 (and hbase-1.3.0+), the integration test clients will make use of the configuration properties `hbase.client.keytab.file` and `hbase.client.kerberos.principal`. They are required. The clients will perform a login from the configured keytab file and automatically refresh the credentials in the background for the process lifetime (See [HBASE-16231](https://issues.apache.org/jira/browse/HBASE-16231)).

#### 13.1.2\. Upgrading Coprocessors to 2.0

Coprocessors have changed substantially in 2.0 ranging from top level design changes in class hierarchies to changed/removed methods, interfaces, etc. (Parent jira: [HBASE-18169 Coprocessor fix and cleanup before 2.0.0 release](https://issues.apache.org/jira/browse/HBASE-18169)). Some of the reasons for such widespread changes:

1.  Pass Interfaces instead of Implementations; e.g. TableDescriptor instead of HTableDescriptor and Region instead of HRegion ([HBASE-18241](https://issues.apache.org/jira/browse/HBASE-18241) Change client.Table and client.Admin to not use HTableDescriptor).

2.  Design refactor so implementers need to fill out less boilerplate and so we can do more compile-time checking ([HBASE-17732](https://issues.apache.org/jira/browse/HBASE-17732))

3.  Purge Protocol Buffers from Coprocessor API ([HBASE-18859](https://issues.apache.org/jira/browse/HBASE-18859), [HBASE-16769](https://issues.apache.org/jira/browse/HBASE-16769), etc)

4.  Cut back on what we expose to Coprocessors removing hooks on internals that were too private to expose (for eg. [HBASE-18453](https://issues.apache.org/jira/browse/HBASE-18453) CompactionRequest should not be exposed to user directly; [HBASE-18298](https://issues.apache.org/jira/browse/HBASE-18298) RegionServerServices Interface cleanup for CP expose; etc)

To use coprocessors in 2.0, they should be rebuilt against new API otherwise they will fail to load and HBase processes will die.

Suggested order of changes to upgrade the coprocessors:

1.  Directly implement observer interfaces instead of extending Base*Observer classes. Change `Foo extends BaseXXXObserver` to `Foo implements XXXObserver`. ([HBASE-17312](https://issues.apache.org/jira/browse/HBASE-17312)).

2.  Adapt to design change from Inheritence to Composition ([HBASE-17732](https://issues.apache.org/jira/browse/HBASE-17732)) by following [this example](https://github.com/apache/hbase/blob/master/dev-support/design-docs/Coprocessor_Design_Improvements-Use_composition_instead_of_inheritance-HBASE-17732.adoc#migrating-existing-cps-to-new-design).

3.  getTable() has been removed from the CoprocessorEnvrionment, coprocessors should self-manage Table instances.

Some examples of writing coprocessors with new API can be found in hbase-example module [here](https://github.com/apache/hbase/tree/branch-2.0/hbase-examples/src/main/java/org/apache/hadoop/hbase/coprocessor/example) .

Lastly, if an api has been changed/removed that breaks you in an irreparable way, and if there’s a good justification to add it back, bring it our notice ([dev@hbase.apache.org](mailto:dev@hbase.apache.org)).

#### 13.1.3\. Rolling Upgrade from 1.x to 2.x

Rolling upgrades are currently an experimental feature. They have had limited testing. There are likely corner cases as yet uncovered in our limited experience so you should be careful if you go this route. The stop/upgrade/start described in the next section, [Upgrade process from 1.x to 2.x](#upgrade2.0.process), is the safest route.

That said, the below is a prescription for a rolling upgrade of a 1.4 cluster.

Pre-Requirements

*   Upgrade to the latest 1.4.x release. Pre 1.4 releases may also work but are not tested, so please upgrade to 1.4.3+ before upgrading to 2.x, unless you are an expert and familiar with the region assignment and crash processing. See the section [Upgrading from pre-1.4 to 1.4+](#upgrade1.4) on how to upgrade to 1.4.x.

*   Make sure that the zk-less assignment is enabled, i.e, set `hbase.assignment.usezk` to `false`. This is the most important thing. It allows the 1.x master to assign/unassign regions to/from 2.x region servers. See the release note section of [HBASE-11059](https://issues.apache.org/jira/browse/HBASE-11059) on how to migrate from zk based assignment to zk less assignment.

*   We have tested rolling upgrading from 1.4.3 to 2.1.0, but it should also work if you want to upgrade to 2.0.x.

Instructions

1.  Unload a region server and upgrade it to 2.1.0\. With [HBASE-17931](https://issues.apache.org/jira/browse/HBASE-17931) in place, the meta region and regions for other system tables will be moved to this region server immediately. If not, please move them manually to the new region server. This is very important because

    *   The schema of meta region is hard coded, if meta is on an old region server, then the new region servers can not access it as it does not have some families, for example, table state.

    *   Client with lower version can communicate with server with higher version, but not vice versa. If the meta region is on an old region server, the new region server will use a client with higher version to communicate with a server with lower version, this may introduce strange problems.

2.  Rolling upgrade all other region servers.

3.  Upgrading masters.

It is OK that during the rolling upgrading there are region server crashes. The 1.x master can assign regions to both 1.x and 2.x region servers, and [HBASE-19166](https://issues.apache.org/jira/browse/HBASE-19166) fixed a problem so that 1.x region server can also read the WALs written by 2.x region server and split them.

> please read the [Changes of Note!](#_changes_of_note) section carefully before rolling upgrading. Make sure that you do not use the removed features in 2.0, for example, the prefix-tree encoding, the old hfile format, etc. They could both fail the upgrading and leave the cluster in an intermediate state and hard to recover.

> If you have success running this prescription, please notify the dev list with a note on your experience and/or update the above with any deviations you may have taken so others going this route can benefit from your efforts.

#### 13.1.4\. Upgrade process from 1.x to 2.x

To upgrade an existing HBase 1.x cluster, you should:

*   Clean shutdown of existing 1.x cluster

*   Update coprocessors

*   Upgrade Master roles first

*   Upgrade RegionServers

*   (Eventually) Upgrade Clients

### 13.2\. Upgrading from pre-1.4 to 1.4+

#### 13.2.1\. Region Server memory consumption changes.

Users upgrading from versions prior to HBase 1.4 should be aware that the estimates of heap usage by the memstore objects (KeyValue, object and array header sizes, etc) have been made more accurate for heap sizes up to 32G (using CompressedOops), resulting in them dropping by 10-50% in practice. This also results in less number of flushes and compactions due to "fatter" flushes. YMMV. As a result, the actual heap usage of the memstore before being flushed may increase by up to 100%. If configured memory limits for the region server had been tuned based on observed usage, this change could result in worse GC behavior or even OutOfMemory errors. Set the environment property (not hbase-site.xml) "hbase.memorylayout.use.unsafe" to false to disable.

#### 13.2.2\. Replication peer’s TableCFs config

Before 1.4, the table name can’t include namespace for replication peer’s TableCFs config. It was fixed by add TableCFs to ReplicationPeerConfig which was stored on Zookeeper. So when upgrade to 1.4, you have to update the original ReplicationPeerConfig data on Zookeeper firstly. There are four steps to upgrade when your cluster have a replication peer with TableCFs config.

*   Disable the replication peer.

*   If master has permission to write replication peer znode, then rolling update master directly. If not, use TableCFsUpdater tool to update the replication peer’s config.

```
$ bin/hbase org.apache.hadoop.hbase.replication.master.TableCFsUpdater update
```

*   Rolling update regionservers.

*   Enable the replication peer.

Notes:

*   Can’t use the old client(before 1.4) to change the replication peer’s config. Because the client will write config to Zookeeper directly, the old client will miss TableCFs config. And the old client write TableCFs config to the old tablecfs znode, it will not work for new version regionserver.

#### 13.2.3\. Raw scan now ignores TTL

Doing a raw scan will now return results that have expired according to TTL settings.

### 13.3\. Upgrading from pre-1.3 to 1.3+

If running Integration Tests under Kerberos, see [Integration Tests and Kerberos](#upgrade2.0.it.kerberos).

### 13.4\. Upgrading to 1.x

Please consult the documentation published specifically for the version of HBase that you are upgrading to for details on the upgrade process.

